name: crawl

on:
  workflow_dispatch:        # 수동 실행 버튼
  schedule:
    - cron: '0 16 * * *'    # 매일 KST 01:00 (UTC 16:00)

jobs:
  run:
    runs-on: self-hosted    # Mac-mini 러너
    env:
      GOOGLE_APPLICATION_CREDENTIALS_B64: ${{ secrets.GOOGLE_APPLICATION_CREDENTIALS_B64 }}

    steps:
      # 1) 저장소 코드 받기
      - uses: actions/checkout@v3

      # 2) 의존 패키지 설치 (mac 기본 python3 사용)
      - name: Install dependencies
        run: |
          python3 -m pip install --upgrade pip
          python3 -m pip install requests beautifulsoup4 gspread google-auth

      # 3) GCP 키(Base64) → service_account.json 복원
      - name: Decode GCP key
        run: |
          echo "$GOOGLE_APPLICATION_CREDENTIALS_B64" | base64 -d > service_account.json

      # 4) 크롤러 실행
      - name: Run crawler
        run: python3 news_crawler_automation.py
